## Awesome-CIL

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/logo.png" style="zoom: 60%;" /></div>
<p></p>
<div align=center><img src="https://visitor-badge.laobi.icu/badge?page_id=Geeks-Z.Awesome-CIL&left_color=green&right_color=red" /> <img src="https://img.shields.io/github/last-commit/Geeks-Z/Awesome-CIL" /> <img src="https://img.shields.io/github/license/Geeks-Z/Awesome-CIL" /></div>

## ğŸ‰ Introduction

- **å¢é‡å­¦ä¹ **ï¼šContinual Learning/Incremental Learning/Life-Long Learning

- **æ±‡æ€»**ç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼ŒClass-Incremental Learningï¼‰çš„è®ºæ–‡å’Œä»£ç ï¼Œå¹¶å¯¹è®ºæ–‡è¿›è¡Œå¤ç°

- **è®ºæ–‡é˜…è¯»ç¬”è®°**ï¼š[è®ºæ–‡é˜…è¯»](https://www.zhihu.com/column/c_1847944474761760768)

## ğŸš€ Survey

| Title                                                        | Venue | Year | Code                                                   |
| ------------------------------------------------------------ | ----- | ---- | ------------------------------------------------------ |
| [Class-Incremental Learning: A Survey](http://arxiv.org/abs/2302.03648) | TPAMI | 2024 | [Official](https://github.com/zhoudw-zdw/CIL_Surve)    |
| [Continual Learning with Pre-Trained Models: A Survey](http://arxiv.org/abs/2401.16386) | IJCAI | 2024 | [Official](https://github.com/sun-hailong/LAMDA-PILOT) |
| [PyCIL: A Python Toolbox for Class-Incremental Learning](https://arxiv.org/abs/2112.12533) |       |      | [Official](https://github.com/G-U-N/PyCIL)              |

## ğŸŒŸ Papers

>åˆ†ç±»å‡†åˆ™åŸºäº [Class-Incremental Learning: A Survey](https://arxiv.org/abs/2302.03648)ï¼Œç¨æœ‰æ”¹åŠ¨ï¼

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241017175011.png" /></div>

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241017175741.png" /></div>

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241017175130.png" /></div>

| Title                                                        | Venue | Year | Type               | Code                                                    |
| ------------------------------------------------------------ | ----- | ---- | ------------------ | ------------------------------------------------------- |
| [MOS: Model Surgery for Pre-Trained Model-Based Class-Incremental Learning](http://arxiv.org/abs/2412.09441) | AAAI  | 2025 | PEFT Expansion     | [Official](https://github.com/sun-hailong/AAAI25-MOS)   |
| [Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning](http://arxiv.org/abs/2403.12030) | CVPR  | 2024 | PEFT Expansion     | [Official](https://github.com/sun-hailong/CVPR24-Ease)  |
| [Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need](https://arxiv.org/pdf/2303.07338) | IJCV  | 2024 | PEFT Expansion     | [Official](https://github.com/zhoudw-zdw/RevisitingCIL) |
| [CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning](http://arxiv.org/abs/2211.13218) | CVPR  | 2023 | PEFT Expansion     | [Official](https://github.com/GT-RIPL/CODA-Prompt)      |
| [DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning](https://arxiv.org/abs/2204.04799) | ECCV  | 2022 | PEFT Expansion     | [Official](https://github.com/google-research/l2p)      |
| [Learning to Prompt for Continual Learning](https://arxiv.org/abs/2112.08654) | CVPR  | 2022 | PEFT Expansion     | [Official](https://github.com/google-research/l2p)      |
| [FOSTER: Feature Boosting and Compression for Class-Incremental Learning](https://arxiv.org/abs/2204.04662) | ECCV  | 2022 | Backbone Expansion | [Official](https://github.com/G-U-N/ECCV22-FOSTER)      |
| [DER: Dynamically Expandable Representation for Class Incremental Learning](2021) | CVPR  | 2021 | Backbone Expansion | [Official](https://github.com/G-U-N/ECCV22-FOSTER)      |
| [iCaRL: Incremental Classifier and Representation Learning](https://arxiv.org/abs/1611.07725) | CVPR  | 2017 | Memory             | [Official](https://github.com/srebuffi/iCaRL)           |

## ğŸ“š Datasets

| Dataset       | training instances | testing instances | Classes | Link                                                         |
| ------------- | ------------------ | ----------------- | ------- | ------------------------------------------------------------ |
| CIFAR100      | 50,000             | 10,000            | 100     |                                                              |
| CUB200        | 9,430              | 2,358             | 200     |                                                              |
| ImageNet-R    | 24,000             | 6,000             | 200     |                                                              |
| ImageNet-A    | 5,981              | 1,519             | 200     |                                                              |
| ObjectNet     | 26,509             | 6,628             | 200     | [https://objectnet.dev/download.html](https://objectnet.dev/download.html) |
| Omnibenchmark | 89,697             | 5,983             | 300     |                                                              |
| VTAB          | 1,796              | 8,619             | 50      |                                                              |

## ğŸ“Š Reproduced Results

> å®éªŒç»“æœï¼šä¸‰æ¬¡å®éªŒçš„å¹³å‡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰å’Œæ ‡å‡†å·®ï¼ˆStdï¼‰/ è®ºæ–‡ä¸­çš„ç»“æœ

### Code

> [LAMDA-PILOT](https://github.com/sun-hailong/LAMDA-PILOT)

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241226204218.png" style="zoom: 80%;" /></div>

### Dataset split

- `B-$m$ Inc-$n$' ï¼š$m$ä»£è¡¨åˆå§‹å¢é‡é˜¶æ®µç±»åˆ«æ•°é‡ï¼Œ$n$ ä»£è¡¨å¢é‡é˜¶æ®µï¼›å¦‚æœ$m=0$ï¼Œåˆ™ä»£è¡¨æ‰€æœ‰ç±»åˆ«å‡åˆ†ä¸º$n$ä¸ªå¢é‡é˜¶æ®µï¼Œå¦‚æœ$m\neq0$ï¼Œåˆ™åˆå§‹é˜¶æ®µä¸º$m$ä¸ªç±»åˆ«ï¼Œå…¶ä»–ç±»åˆ«å‡åˆ†ä¸º$n$ä¸ªå¢é‡é˜¶æ®µï¼›
- LFH(learning from half)ï¼Œè¡¨ç¤ºåœ¨æ¨¡å‹è®­ç»ƒçš„åˆå§‹é˜¶æ®µå…ˆç”¨ä¸€åŠçš„ç±»åˆ«è¿›è¡Œè®­ç»ƒï¼Œç„¶åå‰©ä¸‹ä¸€åŠçš„ç±»åˆ«å‡åŒ€åˆ†ä¸ºNä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼›
- LFS(learning from scratch)ï¼Œè¡¨ç¤ºæ‰€æœ‰çš„ç±»åˆ«å‡åŒ€åœ°åˆ†ä¸ºNä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒ

### Backbone

`ViT-B/16-IN21K`

### Memory

For exemplar parameters, DER, iCaRL and FOSTER set the `fixed_memory` option to false and retain the `memory_size` of 2000 for CIFAR100, while setting `fixed_memory` option to true and retaining the `memory_per_class` of 20 for ImageNet-R. On the contrary, other models are exemplar-free.

### ğŸ—‚ï¸ Dependencies

- pytorch 2.0.1
- torchvision 0.15.2
- timm 0.6.12
- tqdm  4.65.0
- numpy 1.21.5
- scipy 1.10.1
- easydict 1.13

### CIFAR-100

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104174921.png" style="zoom: 80%;" /></div>

|             | B0 Inc5           | B0 Inc10    | B0 Inc20    | B50 Inc5    | B50 Inc10   |
| ----------- |-------------------| ----------- | ----------- | ----------- | ----------- |
|MOS | 94.81 Â± 0.02/93.3 |94.71 Â± 0.05|93.37 Â± 0.07|94.09 Â± 0.0|94.16 Â± 0.01|
|Ease | 93.1 Â± 0.01/91.51 | 92.55 Â± 0.01| 91.64 Â± 0.02| 90.39 Â± 0.03| 89.25 Â± 0.04|
|CODA-Prompt | 92.85 Â± 0.0       |91.56 Â± 0.05|88.87 Â± 0.02|86.09 Â± 0.2|77.74 Â± 0.05|
|DualPrompt | 91.39 Â± 0.01      |90.28 Â± 0.04|88.52 Â± 0.01|87.49 Â± 0.0|81.02 Â± 0.02|
|L2P | 90.72 Â± 0.06      |89.85 Â± 0.01|87.58 Â± 0.0|87.53 Â± 0.06|79.43 Â± 0.01|
|SimpleCIL | 81.12 Â± 0.0       |82.31 Â± 0.0|82.79 Â± 0.0|78.66 Â± 0.0|78.54 Â± 0.0|
|Finetune | 81.48 Â± 0.0       |76.93 Â± 0.0|72.14 Â± 0.0|82.2 Â± 0.0|79.99 Â± 0.0|
|FOSTER-CNN | 93.74 Â± 0.0       |93.68 Â± 0.0|93.71 Â± 0.0|92.2 Â± 0.0|92.15 Â± 0.0|
|FOSTER-NME | 93.7 Â± 0.0        |93.9 Â± 0.0|93.69 Â± 0.0|92.26 Â± 0.0|92.22 Â± 0.0|
|DER-CNN | 88.78 Â± 0.0       |88.58 Â± 0.0|88.63 Â± 0.08|86.92 Â± 0.13|86.55 Â± 0.01|
|DER-NME | 91.36 Â± 0.0       |91.01 Â± 0.0|90.96 Â± 0.15|89.41 Â± 0.04|89.01 Â± 0.05|
|iCaRL-CNN | 87.14 Â± 0.14      |85.91 Â± 0.12|84.43 Â± 0.25|83.4 Â± 0.04|81.32 Â± 0.46|
|iCaRL-NME | 90.8 Â± 0.07       |90.29 Â± 0.05|89.46 Â± 0.02|88.92 Â± 0.06|87.39 Â± 0.23|

### CUB-200

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104175008.png" style="zoom: 80%;" /></div>

|             | B0 Inc5     | B0 Inc10           | B0 Inc20    | B100 Inc5   | B100 Inc10  |
| ----------- | ----------- |--------------------| ----------- | ----------- | ----------- |
|MOS |92.75 Â± 0.0| 93.27 Â± 0.0/93.49  |93.48 Â± 0.0|91.45 Â± 0.0|91.43 Â± 0.0|
|Ease |90.14 Â± 0.05| 90.21 Â± 0.01/92.23 | 91.32 Â± 0.01| 85.26 Â± 0.02| 87.44 Â± 0.07|
|CODA-Prompt |85.78 Â± 0.09| 84.93 Â± 0.05       |83.03 Â± 0.08|79.59 Â± 0.03|76.44 Â± 0.14|
|DualPrompt |85.5 Â± 0.03| 84.84 Â± 0.04       |82.9 Â± 0.08|77.01 Â± 0.07|73.8 Â± 0.1|
|L2P |83.74 Â± 0.04| 81.8 Â± 0.05        |79.33 Â± 0.01|79.15 Â± 0.18|74.65 Â± 0.02|
|SimpleCIL |89.92 Â± 0.0| 90.57 Â± 0.01       |90.96 Â± 0.0|87.51 Â± 0.04|87.43 Â± 0.04|
|Finetune |77.36 Â± 0.49| 70.94 Â± 0.74       |60.21 Â± 2.64|72.88 Â± 0.42|62.32 Â± 2.26|
|FOSTER-CNN |78.81 Â± 0.53| 81.18 Â± 0.36       |85.17 Â± 0.64|82.65 Â± 0.25|85.56 Â± 0.01|
|FOSTER-NME |90.65 Â± 0.05| 91.02 Â± 0.16       |91.4 Â± 0.34|88.92 Â± 0.18|88.72 Â± 0.02|
|DER-CNN |89.08 Â± 0.48| 88.71 Â± 0.86       |90.13 Â± 0.05|87.14 Â± 0.2|86.72 Â± 0.06|
|DER-NME |89.89 Â± 0.19| 89.43 Â± 0.71       |90.99 Â± 0.05|88.62 Â± 0.11|88.34 Â± 0.21|
|iCaRL-CNN |87.77 Â± 0.25| 88.2 Â± 0.13        |88.2 Â± 0.36|85.93 Â± 0.32|85.4 Â± 0.42|
|iCaRL-NME |89.06 Â± 0.04| 89.94 Â± 0.13       |90.2 Â± 0.21|87.91 Â± 0.14|87.25 Â± 0.28|

### ImageNet-R

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104175051.png" style="zoom: 80%;" /></div>

|             | B0 Inc5 | B0 Inc10 | B0 Inc20 | B100 Inc5 | B100 Inc10 |
| ----------- | ------- | -------- | -------- | --------- | ---------- |
|MOS |82.79 Â± 0.0|82.63 Â± 0.0|81.28 Â± 0.0|81.09 Â± 0.0|81.11 Â± 0.0|
|Ease |81.55 Â± 0.04| 81.01 Â± 0.07| 78.88 Â± 0.01| 77.96 Â± 0.01| 76.58 Â± 0.01|
|CODA-Prompt |79.9 Â± 0.06|78.72 Â± 0.06|74.45 Â± 0.13|73.1 Â± 0.03|67.86 Â± 0.02|
|DualPrompt |73.54 Â± 0.02|71.16 Â± 0.13|69.84 Â± 0.06|65.04 Â± 0.16|59.73 Â± 0.13|
|L2P |76.88 Â± 0.02|76.31 Â± 0.04|73.69 Â± 0.01|69.77 Â± 0.05|64.88 Â± 0.0|
|SimpleCIL |65.86 Â± 0.02|67.07 Â± 0.01|67.59 Â± 0.01|63.53 Â± 0.01|63.41 Â± 0.01|
|Finetune |72.24 Â± 0.42|68.32 Â± 0.46|61.95 Â± 1.74|70.73 Â± 0.02|66.72 Â± 0.28|

### ImageNet-A

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104175133.png" style="zoom: 80%;" /></div>

|             | B0 Inc5 | B0 Inc10 | B0 Inc20 | B100 Inc5 | B100 Inc10 |
| ----------- | ------- | -------- | -------- | --------- | ---------- |
|MOS |65.56 Â± 0.0|66.8 Â± 0.0|64.14 Â± 0.0|64.93 Â± 0.0|64.88 Â± 0.0|
|Ease |67.84 Â± 0.08| 62.67 Â± 0.06| 58.13 Â± 0.32| 63.55 Â± 0.35| 62.18 Â± 0.0|
|CODA-Prompt |60.99 Â± 0.01|56.31 Â± 0.17|47.62 Â± 0.11|56.24 Â± 0.26|53.2 Â± 0.2|
|DualPrompt |54.16 Â± 0.1|52.43 Â± 0.03|48.59 Â± 0.1|47.02 Â± 0.11|45.05 Â± 0.33|
|L2P |53.41 Â± 0.12|52.68 Â± 0.08|45.93 Â± 0.18|49.32 Â± 0.14|46.85 Â± 0.08|
|SimpleCIL |58.38 Â± 0.21|59.56 Â± 0.16|60.35 Â± 0.21|53.51 Â± 0.16|53.43 Â± 0.16|
|Finetune |38.03 Â± 0.35|33.73 Â± 1.2|15.26 Â± 5.64|30.32 Â± 0.59|24.65 Â± 0.08|

### Omnibenchmark

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104175214.png" style="zoom: 80%;" /></div>

|             | B0 Inc5     | B0 Inc10    | B0 Inc20    | B0 Inc30    | B150 Inc5   | B150 Inc10  |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
|MOS |85.59 Â± 0.0|85.93 Â± 0.0|85.93 Â± 0.0|86.04 Â± 0.0|83.51 Â± 0.0|83.26 Â± 0.0|
|Ease |75.79 Â± 0.0| 74.84 Â± 0.0| 74.75 Â± 0.0| 74.24 Â± 0.0| 71.68 Â± 0.0| 69.18 Â± 0.0|
|CODA-Prompt |80.04 Â± 0.0|77.01 Â± 0.0|75.14 Â± 0.0|74.31 Â± 0.0|70.36 Â± 0.0|63.14 Â± 0.0|
|DualPrompt |79.37 Â± 0.01|74.93 Â± 0.05|74.84 Â± 0.02|73.58 Â± 0.06|71.51 Â± 0.0|63.95 Â± 0.0|
|L2P |77.99 Â± 0.0|74.15 Â± 0.02|72.72 Â± 0.08|71.13 Â± 0.04|70.17 Â± 0.01|63.38 Â± 0.02|
|SimpleCIL |77.82 Â± 0.07|78.58 Â± 0.05|79.24 Â± 0.04|79.52 Â± 0.04|74.53 Â± 0.04|74.39 Â± 0.05|
|Finetune |70.43 Â± 0.16|65.85 Â± 0.51|60.82 Â± 0.03|57.61 Â± 0.29|68.13 Â± 0.17|64.59 Â± 0.34|
|FOSTER-CNN |77.97 Â± 0.14|78.08 Â± 0.28|81.16 Â± 0.15|81.53 Â± 0.24|79.1 Â± 0.0|79.91 Â± 0.08|
|FOSTER-NME |83.71 Â± 0.21|82.81 Â± 0.27|83.31 Â± 0.12|82.91 Â± 0.07|81.52 Â± 0.14|81.2 Â± 0.04|
|DER-CNN |78.17 Â± 0.48|77.64 Â± 0.08|77.11 Â± 0.33|77.16 Â± 0.0|77.03 Â± 0.16|76.46 Â± 0.04|
|DER-NME |81.72 Â± 0.4|80.78 Â± 0.03|80.09 Â± 0.18|79.24 Â± 0.0|79.55 Â± 0.21|78.65 Â± 0.13|
|iCaRL-CNN |76.43 Â± 0.26|74.73 Â± 0.38|73.81 Â± 0.3|73.15 Â± 0.56|74.11 Â± 0.2|72.38 Â± 0.11|
|iCaRL-NME |82.17 Â± 0.24|80.93 Â± 0.01|80.01 Â± 0.16|79.56 Â± 0.15|79.12 Â± 0.01|78.06 Â± 0.25|

### VTAB

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20250104175243.png" style="zoom: 80%;" /></div>

|             | B0 Inc5 | B0 Inc10          |
| ----------- | ------- |-------------------|
|MOS |92.59 Â± 0.0| 93.18 Â± 0.0/92.62 |
|Ease |90.47 Â± 0.0| 91.07 Â± 0.0/93.61      |
|CODA-Prompt |87.82 Â± 0.0| 83.36 Â± 0.0       |
|DualPrompt |89.96 Â± 0.0| 87.61 Â± 0.0       |
|L2P |82.11 Â± 0.0| 78.04 Â± 0.0       |
|SimpleCIL |90.94 Â± 0.0| 91.66 Â± 0.0       |
|Finetune |78.69 Â± 0.0| 59.2 Â± 0.0        |

> MOS Ease Inc10ç»“æœæ¯”Inc5æ›´å¥½ï¼Ÿ

## ğŸ‘¨â€ğŸ« TODO

| Title                                                                                                                                                   | Venue | Year | Type            | Code                                                        |
|---------------------------------------------------------------------------------------------------------------------------------------------------------| ----- | ---- | --------------- | ----------------------------------------------------------- |
| [InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning](http://arxiv.org/abs/2404.00228)                                                | CVPR  | 2024 | PTM             | [Official](https://github.com/liangyanshuo/InfLoRA)         |
| [FCS: Feature Calibration and Separation for Non-Exemplar Class Incremental Learning](https://ieeexplore.ieee.org/document/10657158/?arnumber=10657158) | CVPR  | 2024 | Feature Rectify | [Official](https://github.com/zhoujiahuan1991/CVPR2024-FCS) |
|                                                                                                                                                     |       |      |                 |                                                             |
|                                                                                                                                                         |       |      |                 |                                                             |

### Different PTMs

| PTM             | Pre-Trained Dataset | Finetuned Dataset |
| --------------- | ------------------- | ----------------- |
| ViT-B/16-IN1K   | ImageNet21K         | ImageNet1K        |
| ViT-B/16-IN21K  | ImageNet21K         | -                 |
| ViT-L/16-IN1K   | ImageNet21K         | ImageNet1K        |
| ViT-B/16-DINO   | ImageNet            | -                 |
| ViT-B/16-SAM    | SA-1B (Segment Anything 1 Billion Dataset) | - |
| ViT-B/16-MAE    | ImageNet21K         | -                 |
| ViT-B/16-CLIP   | OpenAI CLIP Dataset (a large corpus of text-image pairs) | - |
| ResNet18/50/152 | ImageNet1K          | -                 |

### Parameters

> 20Epoch batch_size=48 memory_size: 2000

| Method      | Tunable Parametersï¼ˆBackboneï¼‰ | All Parameters | Average Accuracy (%)<br />(CIFAR B0 Inc5) |
| ----------- | ------------------------------ | -------------- | ----------------------------------------- |
| Ease        |                                |                |                                           |
| SimpleCIL   |                                |                |                                           |
| CODA-Prompt |                                |                |                                           |
| DualPrompt  |                                |                |                                           |
| L2P         |                                |                |                                           |
| FOSTER      |                                |                |                                           |
| DER         |                                |                |                                           |
| iCaRL       |                                |                |                                           |
| Finetune    |                                |                |                                           |

## ğŸ¤— Acknowledgments

- [LAMDA-PILOT](https://github.com/sun-hailong/LAMDA-PILOT)
- [Awesome-Incremental-Learning](https://github.com/xialeiliu/Awesome-Incremental-Learning)
