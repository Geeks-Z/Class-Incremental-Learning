## Awesome-CIL

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/logo.png" style="zoom: 60%;" /></div>
<p></p>
<div align=center><img src="https://visitor-badge.laobi.icu/badge?page_id=Geeks-Z.Awesome-CIL&left_color=green&right_color=red" /> <img src="https://img.shields.io/github/last-commit/Geeks-Z/Awesome-CIL" /> <img src="https://img.shields.io/github/license/Geeks-Z/Awesome-CIL" /></div>

## ğŸ‰ Introduction

- CIL: Class-Incremental Learning ç±»å¢é‡å­¦ä¹ 
- å¢é‡å­¦ä¹ ï¼šContinual Learning/Incremental Learning/Life-Long Learning 

## ğŸš€ Survey

| Title                                                        | Venue | Year | Code                                                   |
| ------------------------------------------------------------ | ----- | ---- | ------------------------------------------------------ |
| [Class-Incremental Learning: A Survey](http://arxiv.org/abs/2302.03648) | TPAMI | 2024 | [Official](https://github.com/zhoudw-zdw/CIL_Surve)    |
| [Continual Learning with Pre-Trained Models: A Survey](http://arxiv.org/abs/2401.16386) | IJCAI | 2024 | [Official](https://github.com/sun-hailong/LAMDA-PILOT) |
| [PyCIL: A Python Toolbox for Class-Incremental Learning](https://arxiv.org/abs/2112.12533) |       |      | [Official](https://github.com/G-U-N/PyCIL)              |

## ğŸŒŸ Papers

| Title                                                        | Venue | Year | Type   | Code                                                    |
| ------------------------------------------------------------ | ----- | ---- | ------ | ------------------------------------------------------- |
| [Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning](http://arxiv.org/abs/2403.12030) | CVPR  | 2024 | PTM    | [Official](https://github.com/sun-hailong/CVPR24-Ease)  |
| [Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need](https://arxiv.org/pdf/2303.07338) | IJCV  | 2024 | PTM    | [Official](https://github.com/zhoudw-zdw/RevisitingCIL) |
| [CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning](http://arxiv.org/abs/2211.13218) | CVPR  | 2023 | PTM    | [Official](https://github.com/GT-RIPL/CODA-Prompt)      |
| [DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning](https://arxiv.org/abs/2204.04799) | ECCV  | 2022 | PTM    | [Official](https://github.com/google-research/l2p)      |
| [Learning to Prompt for Continual Learning](https://arxiv.org/abs/2112.08654) | CVPR  | 2022 | PTM    | [Official](https://github.com/google-research/l2p)      |
| [FOSTER: Feature Boosting and Compression for Class-Incremental Learning](https://arxiv.org/abs/2204.04662) | ECCV  | 2022 | Mixed  | [Official](https://github.com/G-U-N/ECCV22-FOSTER)      |
| [DER: Dynamically Expandable Representation for Class Incremental Learning](2021) | CVPR  | 2021 | Mixed  | [Official](https://github.com/G-U-N/ECCV22-FOSTER)      |
| [iCaRL: Incremental Classifier and Representation Learning](https://arxiv.org/abs/1611.07725) | CVPR  | 2017 | Memory | [Official](https://github.com/srebuffi/iCaRL)           |

## ğŸ“š Datasets

| Dataset       | training instances | testing instances | Classes | Link |
| ------------- | ------------------ | ----------------- | ------- | ---- |
| CIFAR100      | 50,000             | 10,000            | 100     |      |
| CUB200        | 9,430              | 2,358             | 200     |      |
| ImageNet-R    | 24,000             | 6,000             | 200     |      |
| ImageNet-A    | 5,981              | 1,519             | 200     |      |
| ObjectNet     | 26,509             | 6,628             | 200     |      |
| Omnibenchmark | 89,697             | 5,983             | 300     |      |
| VTAB          | 1,796              | 8,619             | 50      |      |

## ğŸ“ Reproduced Results

- class split:
  - `B-$m$ Inc-$n$' . $m$ represents the number of categories in the initial incremental task, while $n$ denotes the number of subsequent incremental tasks, with categories in these tasks evenly distributed. If $m = 0$, all categories in the dataset are evenly distributed across $n$ incremental tasks.
  - LFHå³learning from halfï¼Œè¡¨ç¤ºåœ¨æ¨¡å‹è®­ç»ƒçš„åˆå§‹é˜¶æ®µå…ˆç”¨ä¸€åŠçš„ç±»åˆ«è¿›è¡Œè®­ç»ƒï¼Œç„¶åå‰©ä¸‹ä¸€åŠçš„ç±»åˆ«å‡åŒ€åˆ†ä¸ºNä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒï¼›
  - LFSå³learning from scratchï¼Œè¡¨ç¤ºæ‰€æœ‰çš„ç±»åˆ«å‡åŒ€åœ°åˆ†ä¸ºNä¸ªé˜¶æ®µè¿›è¡Œè®­ç»ƒ
- pre-trained backbone: ViT-B/16-IN21K
- log: 'LAMDA-PILOT-main/res'
- accuracyï¼šCNN/NME
- code: `ğŸ“ LAMDA-PILOT-main`

### CIFAR-100

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241011200729.png" style="zoom: 60%;" /></div>

|             | B0 Inc5     | B0 Inc10    | B0 Inc20    | B50 Inc5    | B50 Inc10   |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
|Ease |93.1 Â± 0.01| 92.55 Â± 0.01| 91.64 Â± 0.02| 90.39 Â± 0.03| 89.25 Â± 0.04|
|SimpleCIL |81.12 Â± 0.0|82.31 Â± 0.0|82.79 Â± 0.0|78.66 Â± 0.0|78.54 Â± 0.0|
|CODA-Prompt |92.85 Â± 0.0|91.56 Â± 0.05|88.87 Â± 0.02|86.09 Â± 0.2|77.74 Â± 0.05|
|DualPrompt |91.39 Â± 0.01|90.28 Â± 0.04|88.52 Â± 0.01|87.49 Â± 0.0|81.02 Â± 0.02|
|L2P |90.72 Â± 0.06|89.85 Â± 0.01|87.58 Â± 0.0|87.53 Â± 0.06|79.43 Â± 0.01|
|FOSTER-CNN |91.33 Â± 0.11|91.5 Â± 0.08|92.02 Â± 0.0|90.56 Â± 0.0|90.82 Â± 0.0|
|FOSTER-NME |93.04 Â± 0.02|92.88 Â± 0.03|92.75 Â± 0.0|91.91 Â± 0.0|91.65 Â± 0.0|
|DER-CNN |88.78 Â± 0.0|88.58 Â± 0.0|88.63 Â± 0.08|86.92 Â± 0.13|86.55 Â± 0.01|
|DER-NME |91.36 Â± 0.0|91.01 Â± 0.0|90.96 Â± 0.15|89.41 Â± 0.04|89.01 Â± 0.05|
|iCaRL-CNN |87.14 Â± 0.14|85.91 Â± 0.12|84.43 Â± 0.25|83.4 Â± 0.04|81.32 Â± 0.46|
|iCaRL-NME |90.8 Â± 0.07|90.29 Â± 0.05|89.46 Â± 0.02|88.92 Â± 0.06|87.39 Â± 0.23|
|Finetune |81.48 Â± 0.0|76.93 Â± 0.0|72.14 Â± 0.0|82.2 Â± 0.0|79.99 Â± 0.0|

### CUB-200

> fixed_memory: True

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20240926214357.png" style="zoom: 60%;" /></div>

|             | B0 Inc5     | B0 Inc10    | B0 Inc20    | B100 Inc5   | B100 Inc10  |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
|Ease |90.14 Â± 0.05| 90.21 Â± 0.01| 91.32 Â± 0.01| 85.26 Â± 0.02| 87.44 Â± 0.07|
|SimpleCIL |89.92 Â± 0.0|90.57 Â± 0.01|90.96 Â± 0.0|87.51 Â± 0.04|87.43 Â± 0.04|
|CODA-Prompt |85.78 Â± 0.09|84.93 Â± 0.05|83.03 Â± 0.08|79.59 Â± 0.03|76.44 Â± 0.14|
|DualPrompt |85.5 Â± 0.03|84.84 Â± 0.04|82.9 Â± 0.08|77.01 Â± 0.07|73.8 Â± 0.1|
|L2P |83.74 Â± 0.04|81.8 Â± 0.05|79.33 Â± 0.01|79.15 Â± 0.18|74.65 Â± 0.02|
|FOSTER-CNN |78.81 Â± 0.53|81.18 Â± 0.36|85.17 Â± 0.64|82.65 Â± 0.25|85.56 Â± 0.01|
|FOSTER-NME |90.65 Â± 0.05|91.02 Â± 0.16|91.4 Â± 0.34|88.92 Â± 0.18|88.72 Â± 0.02|
|DER-CNN |89.08 Â± 0.48|88.71 Â± 0.86|90.13 Â± 0.05|87.14 Â± 0.2|86.72 Â± 0.06|
|DER-NME |89.89 Â± 0.19|89.43 Â± 0.71|90.99 Â± 0.05|88.62 Â± 0.11|88.34 Â± 0.21|
|iCaRL-CNN |87.77 Â± 0.25|88.2 Â± 0.13|88.2 Â± 0.36|85.93 Â± 0.32|85.4 Â± 0.42|
|iCaRL-NME |89.06 Â± 0.04|89.94 Â± 0.13|90.2 Â± 0.21|87.91 Â± 0.14|87.25 Â± 0.28|
|Finetune |77.36 Â± 0.49|70.94 Â± 0.74|60.21 Â± 2.64|72.88 Â± 0.42|62.32 Â± 2.26|

### ImageNet-R

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20240926214533.png" style="zoom: 60%;" /></div>

|             | B0 Inc5 | B0 Inc10 | B0 Inc20 | B100 Inc5 | B100 Inc10 |
| ----------- | ------- | -------- | -------- | --------- | ---------- |
|Ease |81.55 Â± 0.04| 81.01 Â± 0.07| 78.88 Â± 0.01| 77.96 Â± 0.01| 76.58 Â± 0.01|
|SimpleCIL |65.86 Â± 0.02|67.07 Â± 0.01|67.59 Â± 0.01|63.53 Â± 0.01|63.41 Â± 0.01|
|CODA-Prompt |79.9 Â± 0.06|78.72 Â± 0.06|74.45 Â± 0.13|73.1 Â± 0.03|67.86 Â± 0.02|
|DualPrompt |73.54 Â± 0.02|71.16 Â± 0.13|69.84 Â± 0.06|65.04 Â± 0.16|59.73 Â± 0.13|
|L2P |76.88 Â± 0.02|76.31 Â± 0.04|73.69 Â± 0.01|69.77 Â± 0.05|64.88 Â± 0.0|
|Finetune |72.24 Â± 0.42|68.32 Â± 0.46|61.95 Â± 1.74|70.73 Â± 0.02|66.72 Â± 0.28|

### ImageNet-A

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20240926214602.png" style="zoom: 60%;" /></div>

|             | B0 Inc5 | B0 Inc10 | B0 Inc20 | B100 Inc5 | B100 Inc10 |
| ----------- | ------- | -------- | -------- | --------- | ---------- |
|Ease |67.84 Â± 0.08| 62.67 Â± 0.06| 58.13 Â± 0.32| 63.55 Â± 0.35| 62.18 Â± 0.0|
|SimpleCIL |58.38 Â± 0.21|59.56 Â± 0.16|60.35 Â± 0.21|53.51 Â± 0.16|53.43 Â± 0.16|
|CODA-Prompt |60.99 Â± 0.01|56.31 Â± 0.17|47.62 Â± 0.11|56.24 Â± 0.26|53.2 Â± 0.2|
|DualPrompt |54.16 Â± 0.1|52.43 Â± 0.03|48.59 Â± 0.1|47.02 Â± 0.11|45.05 Â± 0.33|
|L2P |53.41 Â± 0.12|52.68 Â± 0.08|45.93 Â± 0.18|49.32 Â± 0.14|46.85 Â± 0.08|
|Finetune |38.03 Â± 0.35|33.73 Â± 1.2|15.26 Â± 5.64|30.32 Â± 0.59|24.65 Â± 0.08|

### Omnibenchmark

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20241121103010.png" style="zoom: 80%;" /></div>

|             | B0 Inc5     | B0 Inc10    | B0 Inc20    | B0 Inc30    | B150 Inc5   | B150 Inc10  |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
|Ease |75.79 Â± 0.0| 74.84 Â± 0.0| 74.75 Â± 0.0| 74.24 Â± 0.0| 71.68 Â± 0.0| 69.18 Â± 0.0|
|CODA-Prompt |80.04 Â± 0.0|77.01 Â± 0.0|75.14 Â± 0.0|74.31 Â± 0.0|70.36 Â± 0.0|63.14 Â± 0.0|
|DualPrompt |79.38 Â± 0.01|74.9 Â± 0.0|74.85 Â± 0.0|73.58 Â± 0.06|71.51 Â± 0.0|63.95 Â± 0.0|
|L2P |77.99 Â± 0.0|74.17 Â± 0.02|72.78 Â± 0.08|71.16 Â± 0.04|70.17 Â± 0.01|63.4 Â± 0.02|
|SimpleCIL |77.82 Â± 0.07|78.58 Â± 0.05|79.24 Â± 0.04|79.52 Â± 0.04|74.53 Â± 0.04|74.39 Â± 0.05|
|Finetune |70.42 Â± 0.15|65.71 Â± 0.45|60.57 Â± 0.34|57.28 Â± 0.41|68.34 Â± 0.25|64.59 Â± 0.35|
|FOSTER-CNN |77.87 Â± 0.0|77.88 Â± 0.0|81.27 Â± 0.0|81.7 Â± 0.0|79.1 Â± 0.0|79.97 Â± 0.0|
|FOSTER-NME |83.86 Â± 0.0|82.62 Â± 0.0|83.4 Â± 0.0|82.96 Â± 0.0|81.42 Â± 0.0|81.17 Â± 0.0|
|DER-CNN |78.14 Â± 0.46|77.69 Â± 0.13|76.85 Â± 0.25|77.16 Â± 0.0|77.14 Â± 0.0|76.49 Â± 0.0|
|DER-NME |81.65 Â± 0.36|80.72 Â± 0.07|79.98 Â± 0.2|79.24 Â± 0.0|79.4 Â± 0.0|78.74 Â± 0.0|
|iCaRL-CNN |76.61 Â± 0.26|75.06 Â± 0.44|73.45 Â± 0.44|73.37 Â± 0.48|76.03 Â± 2.18|72.33 Â± 0.07|
|iCaRL-NME |82.31 Â± 0.22|81.08 Â± 0.22|79.74 Â± 0.33|79.69 Â± 0.17|79.13 Â± 0.01|78.21 Â± 0.31|


### VTAB

<div align=center><img src="https://markdownimg-hw.oss-cn-beijing.aliyuncs.com/20240922193144.png" style="zoom: 60%;" /></div>

|             | B0 Inc5 | B0 Inc10 |
| ----------- | ------- | -------- |
|Ease |90.47 Â± 0.0| 91.07 Â± 0.0|
|SimpleCIL |90.94 Â± 0.0|91.66 Â± 0.0|
|CODA-Prompt |87.82 Â± 0.0|83.36 Â± 0.0|
|DualPrompt |89.96 Â± 0.0|87.61 Â± 0.0|
|L2P |82.11 Â± 0.0|78.04 Â± 0.0|
|Finetune |78.69 Â± 0.0|59.2 Â± 0.0|

### Different  PTMs

| PTM             | Pre-Trained Dataset | Finetuned Dataset |
| --------------- | ------------------- | ----------------- |
| ViT-B/16-IN1K   | ImageNet21K         | ImageNet1K        |
| ViT-B/16-IN21K  | ImageNet21K         | -                 |
| ViT-L/16-IN1K   |                     | ImageNet1K        |
| ViT-B/16-DINO   |                     |                   |
| ViT-B/16-SAM    |                     |                   |
| ViT-B/16-MAE    |                     |                   |
| ViT-B/16CLIP    |                     |                   |
| ResNet18/50/152 |                     |                   |
|                 |                     |                   |

## ğŸ‘¨â€ğŸ«  TODO

| Title                                                        | Venue | Year | Type | Code                                                |
| ------------------------------------------------------------ | ----- | ---- | ---- | --------------------------------------------------- |
| [InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning](http://arxiv.org/abs/2404.00228) | CVPR  | 2024 | PTM  | [Official](https://github.com/liangyanshuo/InfLoRA) |
|                                                              |       |      |      |                                                     |

### â˜„ï¸Parameters

> 20Epoch batch_size=48 memory_size: 2000

| Method      | Tunable Parametersï¼ˆBackboneï¼‰ | All Parameters | Average Accuracy (%)<br />(CIFAR B0 Inc5) |
| ----------- | ------------------------------ | -------------- | ----------------------------------------- |
| Ease        |                                |                |                                           |
| SimpleCIL   |                                |                |                                           |
| CODA-Prompt |                                |                |                                           |
| DualPrompt  |                                |                |                                           |
| L2P         |                                |                |                                           |
| FOSTER      |                                |                |                                           |
| DER         |                                |                |                                           |
| iCaRL       |                                |                |                                           |
| Finetune    |                                |                |                                           |

## ğŸ¤—Acknowledgments

- [LAMDA-PILOT](https://github.com/sun-hailong/LAMDA-PILOT)
- [Awesome-Incremental-Learning](https://github.com/xialeiliu/Awesome-Incremental-Learning)
